{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.optimizers as optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (Conv, Dense, MaxPool, Relu, Flatten)\n",
    "from jax import jit, grad, random,vmap,value_and_grad\n",
    "import jax.nn as jnn\n",
    "from jax.tree_util import tree_multimap\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial # for use with vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parse(record):\n",
    "    features = {\n",
    "        'N': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'labels': tf.io.FixedLenFeature([16], tf.float32),\n",
    "        'elements': tf.io.VarLenFeature(tf.int64),\n",
    "        'coords': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "        serialized=record, features=features)\n",
    "    coords = tf.reshape(tf.sparse.to_dense(parsed_features['coords'], default_value=0),[-1,4])\n",
    "    elements = tf.sparse.to_dense(parsed_features['elements'], default_value=0)\n",
    "    return (elements, coords), parsed_features['labels']\n",
    "data = tf.data.TFRecordDataset(\n",
    "    'qm9.tfrecords', compression_type='GZIP').map(data_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element one hots\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Coordinates\n",
      " [[-1.2698136e-02  1.0858041e+00  8.0009960e-03]\n",
      " [ 2.1504159e-03 -6.0313176e-03  1.9761203e-03]\n",
      " [ 1.0117308e+00  1.4637512e+00  2.7657481e-04]\n",
      " [-5.4081506e-01  1.4475266e+00 -8.7664372e-01]\n",
      " [-5.2381361e-01  1.4379326e+00  9.0639728e-01]]\n",
      "Label: -40.475117\n"
     ]
    }
   ],
   "source": [
    "def convert_record(d):\n",
    "    # break up record\n",
    "    (e, x), y = d\n",
    "    # \n",
    "    e = e.numpy()\n",
    "    x = x.numpy()\n",
    "    r = x[:, :3]    \n",
    "    # use nearest power of 2 (16)\n",
    "    ohc = np.zeros((len(e), 16))\n",
    "    ohc[np.arange(len(e)), e - 1] = 1    \n",
    "    return (ohc, r), y.numpy()[13]\n",
    "\n",
    "for d in data:\n",
    "    (e,x), y = convert_record(d)\n",
    "    print('Element one hots\\n', e)\n",
    "    print('Coordinates\\n', x)\n",
    "    print('Label:', y)\n",
    "    break\n",
    "    \n",
    "def x2e(x):\n",
    "    '''convert xyz coordinates to inverse pairwise distance'''    \n",
    "    r2 = jnp.sum((x - x[:, jnp.newaxis, :])**2, axis=-1)\n",
    "    e = jnp.where(r2 != 0, 1 / r2, 0.)\n",
    "    return e\n",
    "\n",
    "def gnn_layer(nodes, edges, features, we, wv, wu):\n",
    "    '''Implementation of the GNN'''\n",
    "    # make nodes be N x N so we can just multiply directly\n",
    "    ek = jax.nn.relu(\n",
    "        jnp.repeat(nodes[jnp.newaxis,...], nodes.shape[0], axis=0) @ we * edges[...,jnp.newaxis])\n",
    "    ebar = jnp.sum(ek, axis=1)\n",
    "    new_nodes = jax.nn.relu(ebar @ wv) + nodes\n",
    "    \n",
    "    global_node_features = jnp.sum(new_nodes, axis=0)\n",
    "    #print(global_node_features.shape)\n",
    "    new_features = jax.nn.relu(global_node_features  @ wu) + features    \n",
    "    return new_nodes, edges, new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input feautres [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "output features [0.         0.         0.         0.         0.03054902 0.\n",
      " 0.38822997 0.49316457]\n"
     ]
    }
   ],
   "source": [
    "graph_feature_len = 8\n",
    "node_feature_len = 16\n",
    "msg_feature_len = 16\n",
    "\n",
    "# make our weights\n",
    "def init_weights(g, n, m):\n",
    "    we = np.random.normal(size=(n, m), scale=1e-1)\n",
    "    wv = np.random.normal(size=(m, n), scale=1e-1)\n",
    "    wu = np.random.normal(size=(n, g), scale=1e-1)\n",
    "    return we, wv, wu\n",
    "\n",
    "# make a graph\n",
    "nodes = e\n",
    "edges = x2e(x)\n",
    "features = jnp.zeros(graph_feature_len)\n",
    "\n",
    "# eval\n",
    "out = gnn_layer(nodes, edges, features, *init_weights(graph_feature_len, node_feature_len, msg_feature_len))\n",
    "print('input feautres', features)\n",
    "print('output features', out[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_weights(graph_feature_len, node_feature_len, msg_feature_len)\n",
    "w2 = init_weights(graph_feature_len, node_feature_len, msg_feature_len)\n",
    "w3 = np.random.normal(size=(graph_feature_len))\n",
    "b = -325. # starting guess\n",
    "\n",
    "@jax.jit\n",
    "def model(nodes, coords, w1, w2, w3, b):\n",
    "    f0 = jnp.zeros(graph_feature_len)\n",
    "    e0 = x2e(coords)\n",
    "    n0 = nodes\n",
    "    n,e,f = gnn_layer(n0, e0, f0, *w1)\n",
    "    n,e,f = gnn_layer(n, e, f, *w2)\n",
    "    yhat = f @ w3 + b\n",
    "    return yhat\n",
    "\n",
    "def lossA(nodes, coords, y, w1, w2, w3, b):\n",
    "    return (model(nodes, coords, w1, w2, w3, b) - y)**2\n",
    "loss_grad = jax.grad(lossA, (3, 4, 5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 31.86\n",
      "epoch: 1 loss: 31.80\n",
      "epoch: 2 loss: 31.67\n",
      "epoch: 3 loss: 31.44\n",
      "epoch: 4 loss: 31.31\n",
      "epoch: 5 loss: 31.20\n",
      "epoch: 6 loss: 31.06\n",
      "epoch: 7 loss: 30.99\n",
      "epoch: 8 loss: 30.96\n",
      "epoch: 9 loss: 30.77\n",
      "epoch: 10 loss: 30.66\n",
      "epoch: 11 loss: 30.58\n",
      "epoch: 12 loss: 30.44\n",
      "epoch: 13 loss: 30.31\n",
      "epoch: 14 loss: 30.25\n",
      "epoch: 15 loss: 30.15\n"
     ]
    }
   ],
   "source": [
    "test_set = data.take(100)\n",
    "valid_set = data.skip(100).take(10)\n",
    "train_set = data.skip(110).take(50).shuffle(50)\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 32\n",
    "eta = 1e-2\n",
    "val_loss = [0. for _ in range(epochs)]\n",
    "for epoch in range(epochs):\n",
    "    bi = 0\n",
    "    grad_est = None\n",
    "    for d in train_set:         \n",
    "        # do training step\n",
    "        # but do not update\n",
    "        # until have enough points\n",
    "        (e,x), y = convert_record(d)\n",
    "        if grad_est is None:\n",
    "            grad_est = loss_grad(e, x, y, w1, w2, w3, b)\n",
    "        else:\n",
    "            grad_est += loss_grad(e, x, y, w1, w2, w3, b)\n",
    "        bi += 1\n",
    "        if bi == batch_size:\n",
    "            # have enough to update            \n",
    "            # update regression weights\n",
    "            w3 -= eta * grad_est[2]  / batch_size\n",
    "            b -= eta * grad_est[3]  / batch_size\n",
    "            # update GNN weights            \n",
    "            for i,w in [(0, w1), (1, w2)]:\n",
    "                for j, param in enumerate(w):\n",
    "                    param -= eta * grad_est[i][j] / batch_size\n",
    "            # reset tracking of batch index\n",
    "            bi = 0            \n",
    "            grad_est = None            \n",
    "    # compute validation loss    \n",
    "    for v in valid_set:\n",
    "        (e,x), y = convert_record(v)\n",
    "        # convert SE to RMSE\n",
    "        val_loss[epoch] += jnp.sqrt(lossA(e, x, y, w1, w2, w3, b) / 1000)\n",
    "    print('epoch:', epoch, 'loss: {:.2f}'.format(val_loss[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (htff2)",
   "language": "python",
   "name": "htf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
