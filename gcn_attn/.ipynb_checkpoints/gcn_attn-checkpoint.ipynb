{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.optimizers as optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (Conv, Dense, MaxPool, Relu, Flatten)\n",
    "from jax import jit, grad, random,vmap,value_and_grad\n",
    "import jax.nn as jnn\n",
    "from jax.tree_util import tree_multimap\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial # for use with vmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parse(record):\n",
    "    features = {\n",
    "        'N': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'labels': tf.io.FixedLenFeature([16], tf.float32),\n",
    "        'elements': tf.io.VarLenFeature(tf.int64),\n",
    "        'coords': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "        serialized=record, features=features)\n",
    "    coords = tf.reshape(tf.sparse.to_dense(parsed_features['coords'], default_value=0),[-1,4])\n",
    "    elements = tf.sparse.to_dense(parsed_features['elements'], default_value=0)\n",
    "    return (elements, coords), parsed_features['labels']\n",
    "data = tf.data.TFRecordDataset(\n",
    "    'qm9.tfrecords', compression_type='GZIP').map(data_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 1 1 1] [[-1.2698136e-02  1.0858041e+00  8.0009960e-03 -5.3568900e-01]\n",
      " [ 2.1504159e-03 -6.0313176e-03  1.9761203e-03  1.3392100e-01]\n",
      " [ 1.0117308e+00  1.4637512e+00  2.7657481e-04  1.3392200e-01]\n",
      " [-5.4081506e-01  1.4475266e+00 -8.7664372e-01  1.3392299e-01]\n",
      " [-5.2381361e-01  1.4379326e+00  9.0639728e-01  1.3392299e-01]] [ 1.0000000e+00  1.5771181e+02  1.5770998e+02  1.5770699e+02\n",
      "  0.0000000e+00  1.3210000e+01 -3.8769999e-01  1.1710000e-01\n",
      "  5.0480002e-01  3.5364101e+01  4.4748999e-02 -4.0478931e+01\n",
      " -4.0476063e+01 -4.0475117e+01 -4.0498596e+01  6.4689999e+00]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'C':6,'H':1,'O':8,'N':7,'F':9}\n",
    "\n",
    "def make_graph(e,x):\n",
    "    e = e.numpy()\n",
    "    x = x.numpy()\n",
    "    r = x[:,:3]\n",
    "    r2 = np.sum((r - r[:,np.newaxis,:])**2,axis=-1)\n",
    "    edges = np.where(r2!=0, 1/r2,0.0) #[N,N]\n",
    "    nodes = np.zeros((len(e),9))\n",
    "    nodes[np.arange(len(e)), e-1] = 1\n",
    "    return nodes,edges\n",
    "\n",
    "def get_label(y):\n",
    "    return y.numpy()[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9) (5, 5) -40.475117\n",
      "(4, 9) (4, 4) -56.522083\n",
      "(3, 9) (3, 3) -76.400925\n",
      "(4, 9) (4, 4) -77.30458\n",
      "(3, 9) (3, 3) -93.408424\n",
      "(4, 9) (4, 4) -114.479805\n",
      "(8, 9) (8, 8) -79.75972\n",
      "(6, 9) (6, 6) -115.67487\n",
      "(7, 9) (7, 7) -116.60461\n",
      "(6, 9) (6, 6) -132.71362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "data_nodes,data_edges,data_labels = [],[],[]\n",
    "for d in data:\n",
    "    (e,x),y = d\n",
    "    nodes,edges = make_graph(e,x)\n",
    "    label = get_label(y)\n",
    "    \n",
    "    data_nodes.append(nodes)\n",
    "    data_edges.append(edges)\n",
    "    data_labels.append(label)\n",
    "    print (nodes.shape,edges.shape,label)\n",
    "    i +=1\n",
    "    if i ==10:\n",
    "        break\n",
    "        \n",
    "data_nodes = np.asarray(data_nodes)\n",
    "data_edges = np.asarray(data_edges)\n",
    "data_labels = np.asarray(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -40.475117  -56.522083  -76.400925  -77.30458   -93.408424 -114.479805\n",
      "  -79.75972  -115.67487  -116.60461  -132.71362 ]\n"
     ]
    }
   ],
   "source": [
    "print(data_labels)\n",
    "#print(data_nodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn_layer(nodes,edges,train_weights):\n",
    "    \n",
    "    #wq has shape (9,10), output from query has shape (5,10)\n",
    "    query = jnp.dot(nodes,train_weights[0]) \n",
    "    \n",
    "\n",
    "    #pairwise distances are used here wk has shape of (9,10), output from keys has shape (5,5,10)\n",
    "    keys = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[1]) * edges\n",
    "    d_sq = math.sqrt(keys.shape[-1])\n",
    "    b = jnn.softmax(query[jnp.newaxis,...] * keys/d_sq)\n",
    "    \n",
    "    #wv has shape (9,10), output from values has shape (5,5,10)\n",
    "    values = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[2])\n",
    "    \n",
    "    messages = b * values #out shape (5,5,10)\n",
    "    \n",
    "    net_message = jnp.mean(messages,axis= 1)\n",
    "    self_message = nodes @ train_weights[3]\n",
    "    \n",
    "    #self loop\n",
    "    out_nodes = jnn.relu((net_message+self_message)) \n",
    "    \n",
    "    return out_nodes,edges\n",
    "    \n",
    "    \n",
    "def graph_level_fts(nodes):\n",
    "    node_avg = jnp.mean(nodes,axis=1)\n",
    "    return node_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(w,b, x):\n",
    "    \n",
    "    return w*x + b\n",
    "\n",
    "\n",
    "\n",
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23964253 1.9595194  1.9574305  1.9660587  1.9568462 ] (5,)\n",
      "1604.9153 [0.18368527] -40.475117\n"
     ]
    }
   ],
   "source": [
    "out_dim = 10\n",
    "embed_dim = 4\n",
    "\n",
    "#get node embeddings instead of one-hot \n",
    "element_embeddings = np.random.normal(size=(9,embed_dim))\n",
    "embed_nodes = nodes @ element_embeddings\n",
    "\n",
    "#get edge embeddings from pairwise distances\n",
    "edge_embeddings = np.random.normal(size=(1,len(edges),out_dim))\n",
    "embed_edges = edges[...,np.newaxis] * edge_embeddings\n",
    "\n",
    "#trainable weights\n",
    "w1 = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "w2 = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "\n",
    "\n",
    "#call gcn\n",
    "\n",
    "n,e = gcn_layer(embed_nodes,embed_edges,w1)\n",
    "n,e = gcn_layer(embed_nodes,embed_edges,w2)\n",
    "n = graph_level_fts(n)\n",
    "print(n,n.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_init, net_apply = stax.serial(\n",
    "    gcn_layer\n",
    "    Dense(16), Relu,\n",
    "    Dense(1)\n",
    ")\n",
    "\n",
    "rng = random.PRNGKey(0)\n",
    "in_shape = (-1,n.shape[0])\n",
    "\n",
    "out_shape, net_params =net_init(rng,in_shape)\n",
    "#print(net_params)\n",
    "\n",
    "losses = loss(net_params,n,label)\n",
    "#losses = vmap(partial(loss, net_params))(n, label)\n",
    "#print(predictions)\n",
    "print(losses,pred,label)\n",
    "\n",
    "opt_init, opt_update,get_params = optimizers.adam(step_size=1e-2)\n",
    "opt_state = opt_init(net_params)\n",
    "\n",
    "params = get_params(opt_state)\n",
    "\n",
    "up_params, opt_state, loss = update(params, n, label, opt_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "r = np.repeat(nodes[np.newaxis,...],nodes.shape[0],axis=0) @ np.ones((9,10 )) \n",
    "r.shape\n",
    "\n",
    "a = jnp.ones((5,5))\n",
    "b = jnp.ones((5,10))\n",
    "c = a@b\n",
    "\n",
    "print(c.shape)\n",
    "#print(softmax(c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = vmap(partial(net_apply, net_params))(xrange_inputs)\n",
    "losses = vmap(partial(loss, net_params))(xrange_inputs, targets) # per-input loss\n",
    "plt.plot(xrange_inputs, predictions, label='prediction')\n",
    "plt.plot(xrange_inputs, losses, label='loss')\n",
    "plt.plot(xrange_inputs, targets, label='target')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "out_dim = 10\n",
    "input_shape = (5,10)\n",
    "output_shape = input_shape[:-1] + (out_dim,)\n",
    "print(input_shape[:-1])\n",
    "print(output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9) (5, 5) -40.475117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for d in data:\n",
    "    (e,x),y = d\n",
    "    nodes,edges = make_graph(e,x)\n",
    "    label = get_label(y)\n",
    "    print (nodes.shape,edges.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes and weights (5, 4) (4, 10)\n",
      "nodes and weights (5, 4) (4, 10)\n",
      "nodes and weights (5, 10) (4, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Incompatible shapes for dot: got (5, 10) and (4, 10).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-ec2a8342d521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-ec2a8342d521>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(params, inputs, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Computes average loss for the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#todo: add reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/jax/experimental/stax.py\u001b[0m in \u001b[0;36mapply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mrngs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_funs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minit_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-ec2a8342d521>\u001b[0m in \u001b[0;36mapply_fun\u001b[0;34m(train_weights, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nodes and weights'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#pairwise distances are used here wk has shape of (9,10), output from keys has shape (5,5,10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   3048\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mb_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/jax/lax/lax.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision)\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     raise TypeError(\"Incompatible shapes for dot: got {} and {}.\".format(\n\u001b[0;32m--> 600\u001b[0;31m         lhs.shape, rhs.shape))\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (5, 10) and (4, 10)."
     ]
    }
   ],
   "source": [
    "out_dim = 10\n",
    "embed_dim = 4\n",
    "#get node embeddings instead of one-hot \n",
    "element_embeddings = np.random.normal(size=(9,embed_dim))\n",
    "embed_nodes = nodes @ element_embeddings\n",
    "#print(embed_nodes.shape)\n",
    "\n",
    "#get edge embeddings from pairwise distances\n",
    "edge_embeddings = np.random.normal(size=(1,len(edges),out_dim))\n",
    "embed_edges = edges[...,np.newaxis] * edge_embeddings\n",
    "\n",
    "def loss(params, inputs, targets):\n",
    "    # Computes average loss for the batch\n",
    "    predictions = net_apply(params, inputs)\n",
    "    #todo: add reg\n",
    "    return np.mean((targets - predictions)**2)\n",
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)\n",
    "\n",
    "def GCN(out_dim,embed_dim):\n",
    "    def init_fun(rng,input_shape):\n",
    "        output_shape = input_shape[:-1] + (out_dim,)\n",
    "        #trainable weights\n",
    "        w = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "        w1 = w[0]\n",
    "        w2 = w[1]\n",
    "        w3 = w[2]\n",
    "        w4 = w[3]\n",
    "        #w2 = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "        return output_shape, (w1,w2,w3,w4)\n",
    "    \n",
    "    def apply_fun(train_weights,inputs, **kwargs):\n",
    "        #wq has shape (9,10), output from query has shape (5,10)\n",
    "        nodes,edges = inputs\n",
    "        print('nodes and weights',nodes.shape,train_weights[0].shape)\n",
    "        query = jnp.dot(nodes,train_weights[0]) \n",
    "\n",
    "        #pairwise distances are used here wk has shape of (9,10), output from keys has shape (5,5,10)\n",
    "        keys = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[1]) * edges\n",
    "        d_sq = math.sqrt(keys.shape[-1])\n",
    "        b = jnn.softmax(query[jnp.newaxis,...] * keys/d_sq)\n",
    "\n",
    "        #wv has shape (9,10), output from values has shape (5,5,10)\n",
    "        values = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[2])\n",
    "\n",
    "        messages = b * values #out shape (5,5,10)\n",
    "\n",
    "        net_message = jnp.mean(messages,axis= 1)\n",
    "        self_message = nodes @ train_weights[3]\n",
    "\n",
    "        #self loop\n",
    "        #out_nodes = jnp.mean(jnn.relu((net_message+self_message)) )\n",
    "        out_nodes = jnn.relu((net_message+self_message)) \n",
    "        #node_avg = jnp.mean(nodes,axis=1)\n",
    "\n",
    "        return out_nodes,edges\n",
    "    \n",
    "    return init_fun,apply_fun\n",
    "        \n",
    "inputs = (embed_nodes,embed_edges)\n",
    "gcn_init,gcn_apply = GCN(out_dim,embed_dim)\n",
    "out_dims, out_w = gcn_init(out_dim,embed_nodes.shape)\n",
    "n,e = gcn_apply(out_w,inputs)\n",
    "#print(n.shape)\n",
    "\n",
    "net_init, net_apply = stax.serial(\n",
    "    GCN(out_dim,embed_dim),\n",
    "    GCN(out_dim,embed_dim),\n",
    "    Dense(16), Relu,\n",
    "    Dense(1)\n",
    ")\n",
    "\n",
    "rng = random.PRNGKey(0)\n",
    "#in_shape = (-1,n.shape[0])\n",
    "\n",
    "out_shape, net_params =net_init(rng,embed_nodes.shape)\n",
    "#print(embed_nodes.shape,out_shape)\n",
    "\n",
    "inputs = (embed_nodes,embed_edges)\n",
    "\n",
    "\n",
    "losses = loss(net_params,inputs,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(np.asarray(net_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = loss(net_params,n,label)\n",
    "\n",
    "opt_init, opt_update,get_params = optimizers.adam(step_size=1e-2)\n",
    "opt_state = opt_init(net_params)\n",
    "\n",
    "params = get_params(opt_state)\n",
    "\n",
    "up_params, opt_state, loss = update(params, n, label, opt_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (htff2)",
   "language": "python",
   "name": "htf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
