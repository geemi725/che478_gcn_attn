{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.optimizers as optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (Conv, Dense, MaxPool, Relu, Flatten)\n",
    "from jax import jit, grad, random,vmap,value_and_grad\n",
    "import jax.nn as jnn\n",
    "from jax.tree_util import tree_multimap\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial # for use with vmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parse(record):\n",
    "    features = {\n",
    "        'N': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'labels': tf.io.FixedLenFeature([16], tf.float32),\n",
    "        'elements': tf.io.VarLenFeature(tf.int64),\n",
    "        'coords': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "        serialized=record, features=features)\n",
    "    coords = tf.reshape(tf.sparse.to_dense(parsed_features['coords'], default_value=0),[-1,4])\n",
    "    elements = tf.sparse.to_dense(parsed_features['elements'], default_value=0)\n",
    "    return (elements, coords), parsed_features['labels']\n",
    "data = tf.data.TFRecordDataset(\n",
    "    'qm9.tfrecords', compression_type='GZIP').map(data_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 1 1 1] [[-1.2698136e-02  1.0858041e+00  8.0009960e-03 -5.3568900e-01]\n",
      " [ 2.1504159e-03 -6.0313176e-03  1.9761203e-03  1.3392100e-01]\n",
      " [ 1.0117308e+00  1.4637512e+00  2.7657481e-04  1.3392200e-01]\n",
      " [-5.4081506e-01  1.4475266e+00 -8.7664372e-01  1.3392299e-01]\n",
      " [-5.2381361e-01  1.4379326e+00  9.0639728e-01  1.3392299e-01]] [ 1.0000000e+00  1.5771181e+02  1.5770998e+02  1.5770699e+02\n",
      "  0.0000000e+00  1.3210000e+01 -3.8769999e-01  1.1710000e-01\n",
      "  5.0480002e-01  3.5364101e+01  4.4748999e-02 -4.0478931e+01\n",
      " -4.0476063e+01 -4.0475117e+01 -4.0498596e+01  6.4689999e+00]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'C':6,'H':1,'O':8,'N':7,'F':9}\n",
    "\n",
    "def make_graph(e,x):\n",
    "    e = e.numpy()\n",
    "    x = x.numpy()\n",
    "    r = x[:,:3]\n",
    "    r2 = np.sum((r - r[:,np.newaxis,:])**2,axis=-1)\n",
    "    edges = np.where(r2!=0, 1/r2,0.0) #[N,N]\n",
    "    nodes = np.zeros((len(e),9))\n",
    "    nodes[np.arange(len(e)), e-1] = 1\n",
    "    return nodes,edges\n",
    "\n",
    "def get_label(y):\n",
    "    return y.numpy()[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9) (5, 5) -40.475117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gwellawa/.conda/htf2/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    (e,x),y = d\n",
    "    nodes,edges = make_graph(e,x)\n",
    "    label = get_label(y)\n",
    "    print (nodes.shape,edges.shape,label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn_layer(nodes,edges,train_weights):\n",
    "    \n",
    "    #wq has shape (9,10), output from query has shape (5,10)\n",
    "    query = jnp.dot(nodes,train_weights[0]) \n",
    "    \n",
    "\n",
    "    #pairwise distances are used here wk has shape of (9,10), output from keys has shape (5,5,10)\n",
    "    keys = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[1]) * edges\n",
    "    d_sq = math.sqrt(keys.shape[-1])\n",
    "    b = jnn.softmax(query[jnp.newaxis,...] * keys/d_sq)\n",
    "    \n",
    "    #wv has shape (9,10), output from values has shape (5,5,10)\n",
    "    values = jnp.dot(jnp.repeat(nodes[jnp.newaxis,...],nodes.shape[0],axis=0), train_weights[2])\n",
    "    \n",
    "    messages = b * values #out shape (5,5,10)\n",
    "    \n",
    "    net_message = jnp.mean(messages,axis= 1)\n",
    "    self_message = nodes @ train_weights[3]\n",
    "    \n",
    "    #self loop\n",
    "    out_nodes = jnn.relu((net_message+self_message)) \n",
    "    \n",
    "    return out_nodes,edges\n",
    "    \n",
    "    \n",
    "def graph_level_fts(nodes):\n",
    "    node_avg = jnp.mean(nodes,axis=1)\n",
    "    return node_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, inputs, targets):\n",
    "    # Computes average loss for the batch\n",
    "    predictions = net_apply(params, inputs)\n",
    "    \n",
    "    #todo: add reg\n",
    "    return np.mean((targets - predictions)**2)\n",
    "\n",
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23964253 1.9595194  1.9574305  1.9660587  1.9568462 ] (5,)\n",
      "1604.9153 [0.18368527] -40.475117\n"
     ]
    }
   ],
   "source": [
    "out_dim = 10\n",
    "embed_dim = 4\n",
    "\n",
    "#get node embeddings instead of one-hot \n",
    "element_embeddings = np.random.normal(size=(9,embed_dim))\n",
    "embed_nodes = nodes @ element_embeddings\n",
    "\n",
    "#get edge embeddings from pairwise distances\n",
    "edge_embeddings = np.random.normal(size=(1,len(edges),out_dim))\n",
    "embed_edges = edges[...,np.newaxis] * edge_embeddings\n",
    "\n",
    "#trainable weights\n",
    "w1 = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "w2 = np.random.normal(size = (4,embed_dim,out_dim))\n",
    "\n",
    "\n",
    "#call gcn\n",
    "\n",
    "n,e = gcn_layer(embed_nodes,embed_edges,w1)\n",
    "n,e = gcn_layer(embed_nodes,embed_edges,w2)\n",
    "n = graph_level_fts(n)\n",
    "print(n,n.shape)\n",
    "\n",
    "net_init, net_apply = stax.serial(\n",
    "    Dense(16), Relu,\n",
    "    Dense(1)\n",
    ")\n",
    "\n",
    "rng = random.PRNGKey(0)\n",
    "in_shape = (-1,n.shape[0])\n",
    "\n",
    "out_shape, net_params =net_init(rng,in_shape)\n",
    "#print(net_params)\n",
    "\n",
    "losses = loss(net_params,n,label)\n",
    "#losses = vmap(partial(loss, net_params))(n, label)\n",
    "#print(predictions)\n",
    "print(losses,pred,label)\n",
    "\n",
    "opt_init, opt_update,get_params = optimizers.adam(step_size=1e-2)\n",
    "opt_state = opt_init(net_params)\n",
    "\n",
    "params = get_params(opt_state)\n",
    "\n",
    "up_params, opt_state, loss = update(params, n, label, opt_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "r = np.repeat(nodes[np.newaxis,...],nodes.shape[0],axis=0) @ np.ones((9,10 )) \n",
    "r.shape\n",
    "\n",
    "a = jnp.ones((5,5))\n",
    "b = jnp.ones((5,10))\n",
    "c = a@b\n",
    "\n",
    "print(c.shape)\n",
    "#print(softmax(c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = vmap(partial(net_apply, net_params))(xrange_inputs)\n",
    "losses = vmap(partial(loss, net_params))(xrange_inputs, targets) # per-input loss\n",
    "plt.plot(xrange_inputs, predictions, label='prediction')\n",
    "plt.plot(xrange_inputs, losses, label='loss')\n",
    "plt.plot(xrange_inputs, targets, label='target')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (htff2)",
   "language": "python",
   "name": "htf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
